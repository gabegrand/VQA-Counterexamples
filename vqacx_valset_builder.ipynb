{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import yaml\n",
    "import json\n",
    "import click\n",
    "import re\n",
    "import random\n",
    "from IPython.display import Image, display\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch import Tensor\n",
    "import vqa.lib.engine as engine\n",
    "import vqa.lib.utils as utils\n",
    "import vqa.lib.logger as logger\n",
    "import vqa.lib.criterions as criterions\n",
    "import vqa.datasets as datasets\n",
    "import vqa.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('options/cx/counterexamples_default.yaml', 'r') as handle:\n",
    "    options = yaml.load(handle)\n",
    "options['vgenome'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load valset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_examples_list = pickle.load(open('data/vqa2/processed/nans,2000_maxlength,26_minwcount,0_nlp,mcb_pad,right_trainsplit,train/valset.pickle', 'rb'))\n",
    "qid_to_example = {ex['question_id']: ex for ex in val_examples_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188030"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://visualqa.org/data/mscoco/vqa/v2_Complementary_Pairs_val_mscoco.zip\n",
    "comp_pairs = json.load(open(\"data/vqa2/raw/annotations/v2_mscoco_val2014_complementary_pairs.json\", \"r\"))\n",
    "\n",
    "comp_q = {}\n",
    "for q1, q2 in comp_pairs:\n",
    "    comp_q[q1] = q2\n",
    "    comp_q[q2] = q1\n",
    "    \n",
    "len(comp_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load KNNs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://visualqa.org/data/mscoco/vqa/mscoco_val2014_nn_images.json\n",
    "\"\"\"\n",
    "The data is in dictionary format where each key is a COCO image id and each value is a list of 24 COCO image ids \n",
    "which are 24 nearest neighbor images of the key image id sorted in increasing distance, i.e., the first image in \n",
    "the list is the 1st nearest neighbor image and the last image in the list is 24th nearest neighbor image.\n",
    "\"\"\"\n",
    "\n",
    "knns = json.load(open(\"data/coco/knn/mscoco_val2014_nn_images.json\", \"r\"))\n",
    "knns = {int(k):v for k,v in knns.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452014\n",
      "COCO_val2014_000000452014.jpg\n",
      "COCO_val2014_000000452014.jpg\n"
     ]
    }
   ],
   "source": [
    "def coco_name_to_num(name):\n",
    "    assert(name[-4:] == '.jpg')\n",
    "    assert(name[-17] == '_')\n",
    "    return int(name[-16:-4])\n",
    "\n",
    "def coco_num_to_name(num, split='val'):\n",
    "    if len(str(num)) > 12:\n",
    "        raise ValueError\n",
    "    if split == 'train':\n",
    "        return 'COCO_train2014_{}.jpg'.format(str(num).zfill(12))\n",
    "    elif split == 'val':\n",
    "        return 'COCO_val2014_{}.jpg'.format(str(num).zfill(12))\n",
    "    else:\n",
    "        raise ValueError('split must be train or val; got {}'.format(split))\n",
    "    \n",
    "print(coco_name_to_num('COCO_val2014_000000452014.jpg'))\n",
    "print(coco_num_to_name(452014))\n",
    "print(coco_num_to_name(452014, 'val'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter down examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique q_ids in the complimentary pairs data\n",
    "q_ids_alpha = []\n",
    "for q1, q2 in comp_pairs:\n",
    "    q_ids_alpha.append(q1)\n",
    "    q_ids_alpha.append(q2)\n",
    "q_ids_alpha_set = set(q_ids_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique q_ids in the VQA2 valing data\n",
    "q_id_to_example = {ex['question_id']: ex for ex in val_examples_list}\n",
    "q_ids_beta_set = set(q_id_to_example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12280619909122292\n"
     ]
    }
   ],
   "source": [
    "# Approx 1.23% of the val example q_ids are not present in the complimentary pairs data\n",
    "print(1 - len(q_ids_alpha_set) / len(q_ids_beta_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188030 26324 0\n"
     ]
    }
   ],
   "source": [
    "# Additionally, the alpha and beta sets are only partially overlapping\n",
    "intersection = q_ids_alpha_set.intersection(q_ids_beta_set)\n",
    "print(len(intersection), len(q_ids_beta_set - q_ids_alpha_set), len(q_ids_alpha_set - q_ids_beta_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118499"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_examples_filtered = []\n",
    "\n",
    "for ex in val_examples_list:\n",
    "    \n",
    "    q1 = ex['question_id']\n",
    "    i1 = coco_name_to_num(ex['image_name'])\n",
    "    \n",
    "    # Ensure q1 has a compliment\n",
    "    if q1 in intersection:\n",
    "        q2 = comp_q[q1]\n",
    "        \n",
    "        # Ensure q2 has a compliment and is in the valing data\n",
    "        if q2 in intersection:\n",
    "            \n",
    "            ex2 = qid_to_example[q2]\n",
    "            i2 = coco_name_to_num(ex2['image_name'])\n",
    "            \n",
    "            # Ensure i2 is in i1's KNNs\n",
    "            if i2 in knns[i1]:\n",
    "                \n",
    "                ex['comp'] = ex2\n",
    "                ex['comp']['knn_index'] = knns[i1].index(i2)\n",
    "                ex['knns'] = [coco_num_to_name(i) for i in knns[i1]]\n",
    "                \n",
    "                val_examples_filtered.append(ex)\n",
    "            \n",
    "len(val_examples_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39998\n",
      "0 506\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: ensure all images in the filtered valset are accounted for in the KNNs data\n",
    "\n",
    "# All unique image ids in filtered valset\n",
    "v_nums_charlie = set([coco_name_to_num(ex['image_name']) for ex in val_examples_filtered])\n",
    "\n",
    "# All unique image ids in KNNs data\n",
    "v_nums_delta = set(knns.keys())\n",
    "\n",
    "# Number of unique image ids\n",
    "v_nums_intersection = v_nums_charlie.intersection(v_nums_delta)\n",
    "print(len(v_nums_intersection))\n",
    "\n",
    "# As expected, all images in the filtered valset are accounted for in the KNNs data\n",
    "print(len(v_nums_charlie - v_nums_delta), len(v_nums_delta - v_nums_charlie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.Random(123).shuffle(val_examples_filtered)\n",
    "\n",
    "pickle.dump(val_examples_filtered, open( \"valset_augmented.pickle\", \"wb\" ) )\n",
    "pickle.dump(val_examples_filtered[:10000], open( \"valset_augmented_small.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
